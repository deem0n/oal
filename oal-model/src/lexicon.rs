use chumsky::{prelude::*, Stream};
use std::fmt::{Debug, Display, Formatter};
use string_interner::{DefaultSymbol, StringInterner};

pub type Span = std::ops::Range<usize>;

pub type Symbol = DefaultSymbol;

pub trait Interner {
    fn register<T: AsRef<str>>(&mut self, s: T) -> Symbol;
    fn resolve(&self, sym: Symbol) -> &str;
}

pub trait Interned {
    fn copy<I: Interner>(&self, from: &I, to: &mut I) -> Self;
}

// Note: we need those bounds on the trait itself to deal with the
// incorrect bounds generated by derive (https://github.com/rust-lang/rust/issues/26925).
pub trait Lexicon: Copy + Clone + Default + Debug {
    type Kind: Copy + Clone + PartialEq + Debug;
    type Value: Debug + Interned;
}

pub type Token<L> = (<L as Lexicon>::Kind, <L as Lexicon>::Value);

pub type TokenIdx = generational_token_list::ItemToken;

pub type TokenSpan<L> = (Token<L>, Span);

#[derive(Copy, Clone, PartialEq, Eq, Hash, Debug)]
pub struct TokenAlias<L: Lexicon>(L::Kind, TokenIdx);

impl<L: Lexicon> TokenAlias<L> {
    pub fn from(kind: L::Kind, idx: TokenIdx) -> Self {
        TokenAlias(kind, idx)
    }

    pub fn kind(&self) -> L::Kind {
        self.0
    }

    pub fn index(&self) -> TokenIdx {
        self.1
    }
}

impl<L: Lexicon> Display for TokenAlias<L> {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        write!(f, "{:#?}", self.0)
    }
}

type ListArena<L> = generational_token_list::GenerationalTokenList<(Token<L>, Span)>;

#[derive(Debug, Default)]
pub struct TokenList<L: Lexicon> {
    list: ListArena<L>,
    dict: StringInterner,
}

impl<L: Lexicon> Interner for TokenList<L> {
    fn register<T: AsRef<str>>(&mut self, s: T) -> Symbol {
        self.dict.get_or_intern(s)
    }

    fn resolve(&self, sym: Symbol) -> &str {
        self.dict.resolve(sym).unwrap()
    }
}

impl<L> TokenList<L>
where
    L: Lexicon,
{
    pub fn get(&self, id: TokenIdx) -> &TokenSpan<L> {
        self.list.get(id).unwrap()
    }

    pub fn push(&mut self, t: TokenSpan<L>) -> TokenIdx {
        self.list.push_back(t)
    }

    pub fn len(&self) -> usize {
        self.list.tail().map_or(0, |(_, r)| r.end() + 1)
    }

    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn stream<'a, F>(
        &'a self,
        filter: F,
    ) -> Stream<TokenAlias<L>, Span, impl Iterator<Item = (TokenAlias<L>, Span)> + 'a>
    where
        F: Fn(L::Kind) -> bool + 'a,
    {
        let len = self.len();
        // Prepare the parser iterator by ignoring trivia tokens and replacing values by indices.
        let iter =
            self.list
                .iter_with_tokens()
                .filter_map(move |(index, ((kind, _value), span))| {
                    filter(*kind).then(|| (TokenAlias::from(*kind, index), span.clone()))
                });
        Stream::from_iter(len..len + 1, iter)
    }
}
